{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nfrom PIL import Image\nfrom tqdm import tqdm\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-28T18:24:30.631479Z","iopub.execute_input":"2021-08-28T18:24:30.631820Z","iopub.status.idle":"2021-08-28T18:24:30.636947Z","shell.execute_reply.started":"2021-08-28T18:24:30.631790Z","shell.execute_reply":"2021-08-28T18:24:30.635118Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def atoi(s):\n    n = 0\n    for i in s:\n        n = n*10 + ord(i) - ord(\"0\")\n    return n","metadata":{"execution":{"iopub.status.busy":"2021-08-28T18:24:31.129353Z","iopub.execute_input":"2021-08-28T18:24:31.129671Z","iopub.status.idle":"2021-08-28T18:24:31.134080Z","shell.execute_reply.started":"2021-08-28T18:24:31.129642Z","shell.execute_reply":"2021-08-28T18:24:31.133068Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"outer_names = ['test','train']\ninner_names = ['angry', 'disgusted', 'fearful', 'happy', 'sad', 'surprised', 'neutral']\nos.makedirs('data', exist_ok=True)\nfor outer_name in outer_names:\n    os.makedirs(os.path.join('data',outer_name), exist_ok=True)\n    for inner_name in inner_names:\n        os.makedirs(os.path.join('data',outer_name,inner_name), exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T18:24:31.650911Z","iopub.execute_input":"2021-08-28T18:24:31.651264Z","iopub.status.idle":"2021-08-28T18:24:31.656938Z","shell.execute_reply.started":"2021-08-28T18:24:31.651229Z","shell.execute_reply":"2021-08-28T18:24:31.656041Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"angry = 0\ndisgusted = 0\nfearful = 0\nhappy = 0\nsad = 0\nsurprised = 0\nneutral = 0\nangry_test = 0\ndisgusted_test = 0\nfearful_test = 0\nhappy_test = 0\nsad_test = 0\nsurprised_test = 0\nneutral_test = 0","metadata":{"execution":{"iopub.status.busy":"2021-08-28T18:24:32.698769Z","iopub.execute_input":"2021-08-28T18:24:32.699099Z","iopub.status.idle":"2021-08-28T18:24:32.704406Z","shell.execute_reply.started":"2021-08-28T18:24:32.699066Z","shell.execute_reply":"2021-08-28T18:24:32.703202Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/fer2013/fer2013.csv')\nmat = np.zeros((48,48),dtype=np.uint8)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T18:24:33.679458Z","iopub.execute_input":"2021-08-28T18:24:33.679774Z","iopub.status.idle":"2021-08-28T18:24:36.068707Z","shell.execute_reply.started":"2021-08-28T18:24:33.679745Z","shell.execute_reply":"2021-08-28T18:24:36.067620Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T18:24:36.070272Z","iopub.execute_input":"2021-08-28T18:24:36.070671Z","iopub.status.idle":"2021-08-28T18:24:36.081394Z","shell.execute_reply.started":"2021-08-28T18:24:36.070618Z","shell.execute_reply":"2021-08-28T18:24:36.080589Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"   emotion                                             pixels     Usage\n0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emotion</th>\n      <th>pixels</th>\n      <th>Usage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n      <td>Training</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"for i in tqdm(range(len(df))):\n    txt = df['pixels'][i]\n    words = txt.split()\n    \n    for j in range(2304):\n        xind = j // 48\n        yind = j % 48\n        mat[xind][yind] = atoi(words[j])\n\n    img = Image.fromarray(mat)\n\n    if i < 28709:\n        if df['emotion'][i] == 0:\n            img.save('data/train/angry/im'+str(angry)+'.png')\n            angry += 1\n        elif df['emotion'][i] == 1:\n            img.save('data/train/disgusted/im'+str(disgusted)+'.png')\n            disgusted += 1\n        elif df['emotion'][i] == 2:\n            img.save('data/train/fearful/im'+str(fearful)+'.png')\n            fearful += 1\n        elif df['emotion'][i] == 3:\n            img.save('data/train/happy/im'+str(happy)+'.png')\n            happy += 1\n        elif df['emotion'][i] == 4:\n            img.save('data/train/sad/im'+str(sad)+'.png')\n            sad += 1\n        elif df['emotion'][i] == 5:\n            img.save('data/train/surprised/im'+str(surprised)+'.png')\n            surprised += 1\n        elif df['emotion'][i] == 6:\n            img.save('data/train/neutral/im'+str(neutral)+'.png')\n            neutral += 1\n\n    else:\n        if df['emotion'][i] == 0:\n            img.save('data/test/angry/im'+str(angry_test)+'.png')\n            angry_test += 1\n        elif df['emotion'][i] == 1:\n            img.save('data/test/disgusted/im'+str(disgusted_test)+'.png')\n            disgusted_test += 1\n        elif df['emotion'][i] == 2:\n            img.save('data/test/fearful/im'+str(fearful_test)+'.png')\n            fearful_test += 1\n        elif df['emotion'][i] == 3:\n            img.save('data/test/happy/im'+str(happy_test)+'.png')\n            happy_test += 1\n        elif df['emotion'][i] == 4:\n            img.save('data/test/sad/im'+str(sad_test)+'.png')\n            sad_test += 1\n        elif df['emotion'][i] == 5:\n            img.save('data/test/surprised/im'+str(surprised_test)+'.png')\n            surprised_test += 1\n        elif df['emotion'][i] == 6:\n            img.save('data/test/neutral/im'+str(neutral_test)+'.png')\n            neutral_test += 1\n","metadata":{"execution":{"iopub.status.busy":"2021-08-28T18:24:36.083209Z","iopub.execute_input":"2021-08-28T18:24:36.083750Z","iopub.status.idle":"2021-08-28T18:27:16.356473Z","shell.execute_reply.started":"2021-08-28T18:24:36.083708Z","shell.execute_reply":"2021-08-28T18:27:16.355438Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"100%|██████████| 35887/35887 [02:40<00:00, 223.95it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Now the traing begin**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport argparse\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'","metadata":{"execution":{"iopub.status.busy":"2021-08-28T18:27:29.851856Z","iopub.execute_input":"2021-08-28T18:27:29.852203Z","iopub.status.idle":"2021-08-28T18:27:29.858254Z","shell.execute_reply.started":"2021-08-28T18:27:29.852156Z","shell.execute_reply":"2021-08-28T18:27:29.857030Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def plot_model_history(model_history):\n    \"\"\"\n    Plot Accuracy and Loss curves given the model_history\n    \"\"\"\n    fig, axs = plt.subplots(1,2,figsize=(15,5))\n    # summarize history for accuracy\n    axs[0].plot(range(1,len(model_history.history['accuracy'])+1),model_history.history['accuracy'])\n    axs[0].plot(range(1,len(model_history.history['val_accuracy'])+1),model_history.history['val_accuracy'])\n    axs[0].set_title('Model Accuracy')\n    axs[0].set_ylabel('Accuracy')\n    axs[0].set_xlabel('Epoch')\n    axs[0].set_xticks(np.arange(1,len(model_history.history['accuracy'])+1),len(model_history.history['accuracy'])/10)\n    axs[0].legend(['train', 'val'], loc='best')\n    # summarize history for loss\n    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n    axs[1].set_title('Model Loss')\n    axs[1].set_ylabel('Loss')\n    axs[1].set_xlabel('Epoch')\n    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n    axs[1].legend(['train', 'val'], loc='best')\n    fig.savefig('plot.png')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T18:27:31.109665Z","iopub.execute_input":"2021-08-28T18:27:31.109997Z","iopub.status.idle":"2021-08-28T18:27:31.120469Z","shell.execute_reply.started":"2021-08-28T18:27:31.109966Z","shell.execute_reply":"2021-08-28T18:27:31.119232Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"train_dir = './data/train'\nval_dir = './data/test'","metadata":{"execution":{"iopub.status.busy":"2021-08-28T18:27:32.394154Z","iopub.execute_input":"2021-08-28T18:27:32.394567Z","iopub.status.idle":"2021-08-28T18:27:32.398731Z","shell.execute_reply.started":"2021-08-28T18:27:32.394533Z","shell.execute_reply":"2021-08-28T18:27:32.397466Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"num_train = 28709\nnum_val = 7178\nbatch_size = 64\nnum_epoch = 250","metadata":{"execution":{"iopub.status.busy":"2021-08-28T18:27:33.479890Z","iopub.execute_input":"2021-08-28T18:27:33.480236Z","iopub.status.idle":"2021-08-28T18:27:33.484318Z","shell.execute_reply.started":"2021-08-28T18:27:33.480183Z","shell.execute_reply":"2021-08-28T18:27:33.483130Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255)\nval_datagen = ImageDataGenerator(rescale=1./255)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T18:27:36.994510Z","iopub.execute_input":"2021-08-28T18:27:36.994925Z","iopub.status.idle":"2021-08-28T18:27:37.003620Z","shell.execute_reply.started":"2021-08-28T18:27:36.994886Z","shell.execute_reply":"2021-08-28T18:27:37.002627Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(48,48),\n        batch_size=batch_size,\n        color_mode=\"grayscale\",\n        class_mode='categorical')\n\nvalidation_generator = val_datagen.flow_from_directory(\n        val_dir,\n        target_size=(48,48),\n        batch_size=batch_size,\n        color_mode=\"grayscale\",\n        class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2021-08-28T18:27:38.318107Z","iopub.execute_input":"2021-08-28T18:27:38.318486Z","iopub.status.idle":"2021-08-28T18:27:40.228914Z","shell.execute_reply.started":"2021-08-28T18:27:38.318454Z","shell.execute_reply":"2021-08-28T18:27:40.228127Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Found 28709 images belonging to 7 classes.\nFound 7178 images belonging to 7 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(7, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2021-08-28T18:27:40.994071Z","iopub.execute_input":"2021-08-28T18:27:40.994415Z","iopub.status.idle":"2021-08-28T18:27:42.920698Z","shell.execute_reply.started":"2021-08-28T18:27:40.994385Z","shell.execute_reply":"2021-08-28T18:27:42.919862Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0001, decay=1e-6),metrics=['accuracy'])\nmodel_info = model.fit_generator(\n        train_generator,\n        steps_per_epoch=num_train // batch_size,\n        epochs=num_epoch,\n        validation_data=validation_generator,\n        validation_steps=num_val // batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T18:27:46.672781Z","iopub.execute_input":"2021-08-28T18:27:46.673095Z","iopub.status.idle":"2021-08-28T19:09:18.514455Z","shell.execute_reply.started":"2021-08-28T18:27:46.673065Z","shell.execute_reply":"2021-08-28T19:09:18.513621Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  warnings.warn('`Model.fit_generator` is deprecated and '\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/250\n448/448 [==============================] - 18s 24ms/step - loss: 1.8253 - accuracy: 0.2464 - val_loss: 1.7083 - val_accuracy: 0.3524\nEpoch 2/250\n448/448 [==============================] - 10s 22ms/step - loss: 1.6561 - accuracy: 0.3514 - val_loss: 1.5469 - val_accuracy: 0.4120\nEpoch 3/250\n448/448 [==============================] - 10s 22ms/step - loss: 1.5445 - accuracy: 0.4055 - val_loss: 1.4687 - val_accuracy: 0.4450\nEpoch 4/250\n448/448 [==============================] - 10s 22ms/step - loss: 1.4855 - accuracy: 0.4277 - val_loss: 1.4045 - val_accuracy: 0.4728\nEpoch 5/250\n448/448 [==============================] - 10s 23ms/step - loss: 1.4015 - accuracy: 0.4656 - val_loss: 1.3479 - val_accuracy: 0.4894\nEpoch 6/250\n448/448 [==============================] - 10s 22ms/step - loss: 1.3518 - accuracy: 0.4863 - val_loss: 1.2969 - val_accuracy: 0.5064\nEpoch 7/250\n448/448 [==============================] - 9s 21ms/step - loss: 1.2996 - accuracy: 0.5053 - val_loss: 1.2711 - val_accuracy: 0.5198\nEpoch 8/250\n448/448 [==============================] - 10s 23ms/step - loss: 1.2639 - accuracy: 0.5248 - val_loss: 1.2442 - val_accuracy: 0.5296\nEpoch 9/250\n448/448 [==============================] - 10s 22ms/step - loss: 1.2211 - accuracy: 0.5360 - val_loss: 1.2116 - val_accuracy: 0.5462\nEpoch 10/250\n448/448 [==============================] - 10s 22ms/step - loss: 1.1895 - accuracy: 0.5555 - val_loss: 1.1906 - val_accuracy: 0.5529\nEpoch 11/250\n448/448 [==============================] - 10s 23ms/step - loss: 1.1660 - accuracy: 0.5610 - val_loss: 1.1720 - val_accuracy: 0.5572\nEpoch 12/250\n448/448 [==============================] - 10s 22ms/step - loss: 1.1408 - accuracy: 0.5746 - val_loss: 1.1563 - val_accuracy: 0.5636\nEpoch 13/250\n448/448 [==============================] - 10s 22ms/step - loss: 1.1089 - accuracy: 0.5904 - val_loss: 1.1395 - val_accuracy: 0.5752\nEpoch 14/250\n448/448 [==============================] - 10s 22ms/step - loss: 1.0866 - accuracy: 0.5954 - val_loss: 1.1286 - val_accuracy: 0.5802\nEpoch 15/250\n448/448 [==============================] - 10s 23ms/step - loss: 1.0489 - accuracy: 0.6082 - val_loss: 1.1129 - val_accuracy: 0.5824\nEpoch 16/250\n448/448 [==============================] - 10s 22ms/step - loss: 1.0366 - accuracy: 0.6139 - val_loss: 1.1105 - val_accuracy: 0.5858\nEpoch 17/250\n448/448 [==============================] - 9s 21ms/step - loss: 1.0185 - accuracy: 0.6179 - val_loss: 1.0967 - val_accuracy: 0.5914\nEpoch 18/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.9822 - accuracy: 0.6360 - val_loss: 1.0900 - val_accuracy: 0.5914\nEpoch 19/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.9620 - accuracy: 0.6465 - val_loss: 1.0791 - val_accuracy: 0.5942\nEpoch 20/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.9483 - accuracy: 0.6477 - val_loss: 1.0769 - val_accuracy: 0.5986\nEpoch 21/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.9215 - accuracy: 0.6619 - val_loss: 1.0658 - val_accuracy: 0.6032\nEpoch 22/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.9033 - accuracy: 0.6674 - val_loss: 1.0574 - val_accuracy: 0.6099\nEpoch 23/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.8761 - accuracy: 0.6782 - val_loss: 1.0642 - val_accuracy: 0.6031\nEpoch 24/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.8517 - accuracy: 0.6828 - val_loss: 1.0618 - val_accuracy: 0.6081\nEpoch 25/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.8419 - accuracy: 0.6907 - val_loss: 1.0532 - val_accuracy: 0.6136\nEpoch 26/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.8051 - accuracy: 0.7063 - val_loss: 1.0524 - val_accuracy: 0.6134\nEpoch 27/250\n448/448 [==============================] - 10s 21ms/step - loss: 0.7753 - accuracy: 0.7172 - val_loss: 1.0523 - val_accuracy: 0.6158\nEpoch 28/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.7544 - accuracy: 0.7278 - val_loss: 1.0628 - val_accuracy: 0.6141\nEpoch 29/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.7288 - accuracy: 0.7350 - val_loss: 1.0500 - val_accuracy: 0.6180\nEpoch 30/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.7134 - accuracy: 0.7398 - val_loss: 1.0502 - val_accuracy: 0.6187\nEpoch 31/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.6917 - accuracy: 0.7463 - val_loss: 1.0641 - val_accuracy: 0.6219\nEpoch 32/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.6713 - accuracy: 0.7555 - val_loss: 1.0583 - val_accuracy: 0.6207\nEpoch 33/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.6427 - accuracy: 0.7674 - val_loss: 1.0691 - val_accuracy: 0.6265\nEpoch 34/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.6377 - accuracy: 0.7686 - val_loss: 1.0702 - val_accuracy: 0.6295\nEpoch 35/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.6030 - accuracy: 0.7800 - val_loss: 1.0782 - val_accuracy: 0.6256\nEpoch 36/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.5807 - accuracy: 0.7895 - val_loss: 1.0826 - val_accuracy: 0.6257\nEpoch 37/250\n448/448 [==============================] - 10s 21ms/step - loss: 0.5715 - accuracy: 0.7912 - val_loss: 1.0925 - val_accuracy: 0.6203\nEpoch 38/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.5542 - accuracy: 0.7953 - val_loss: 1.1012 - val_accuracy: 0.6215\nEpoch 39/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.5361 - accuracy: 0.8085 - val_loss: 1.1042 - val_accuracy: 0.6257\nEpoch 40/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.5123 - accuracy: 0.8146 - val_loss: 1.0976 - val_accuracy: 0.6363\nEpoch 41/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.4956 - accuracy: 0.8203 - val_loss: 1.1223 - val_accuracy: 0.6330\nEpoch 42/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.4779 - accuracy: 0.8290 - val_loss: 1.1380 - val_accuracy: 0.6328\nEpoch 43/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.4719 - accuracy: 0.8336 - val_loss: 1.1224 - val_accuracy: 0.6345\nEpoch 44/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.4494 - accuracy: 0.8379 - val_loss: 1.1440 - val_accuracy: 0.6289\nEpoch 45/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.4371 - accuracy: 0.8408 - val_loss: 1.1400 - val_accuracy: 0.6317\nEpoch 46/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.4186 - accuracy: 0.8492 - val_loss: 1.1526 - val_accuracy: 0.6297\nEpoch 47/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.4008 - accuracy: 0.8552 - val_loss: 1.1787 - val_accuracy: 0.6341\nEpoch 48/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.3942 - accuracy: 0.8609 - val_loss: 1.1649 - val_accuracy: 0.6324\nEpoch 49/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.3742 - accuracy: 0.8649 - val_loss: 1.1968 - val_accuracy: 0.6328\nEpoch 50/250\n448/448 [==============================] - 10s 21ms/step - loss: 0.3762 - accuracy: 0.8653 - val_loss: 1.1954 - val_accuracy: 0.6332\nEpoch 51/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.3523 - accuracy: 0.8753 - val_loss: 1.1973 - val_accuracy: 0.6295\nEpoch 52/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.3323 - accuracy: 0.8824 - val_loss: 1.2166 - val_accuracy: 0.6318\nEpoch 53/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.3351 - accuracy: 0.8808 - val_loss: 1.2095 - val_accuracy: 0.6310\nEpoch 54/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.3196 - accuracy: 0.8858 - val_loss: 1.2375 - val_accuracy: 0.6324\nEpoch 55/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.3160 - accuracy: 0.8865 - val_loss: 1.2210 - val_accuracy: 0.6317\nEpoch 56/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.2962 - accuracy: 0.8941 - val_loss: 1.2485 - val_accuracy: 0.6289\nEpoch 57/250\n448/448 [==============================] - 9s 21ms/step - loss: 0.2976 - accuracy: 0.8942 - val_loss: 1.2582 - val_accuracy: 0.6334\nEpoch 58/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.2955 - accuracy: 0.8936 - val_loss: 1.2899 - val_accuracy: 0.6338\nEpoch 59/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.2795 - accuracy: 0.9023 - val_loss: 1.2813 - val_accuracy: 0.6324\nEpoch 60/250\n448/448 [==============================] - 10s 21ms/step - loss: 0.2632 - accuracy: 0.9079 - val_loss: 1.3019 - val_accuracy: 0.6324\nEpoch 61/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.2720 - accuracy: 0.9068 - val_loss: 1.2878 - val_accuracy: 0.6357\nEpoch 62/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.2614 - accuracy: 0.9056 - val_loss: 1.3061 - val_accuracy: 0.6307\nEpoch 63/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.2497 - accuracy: 0.9125 - val_loss: 1.3343 - val_accuracy: 0.6317\nEpoch 64/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.2444 - accuracy: 0.9142 - val_loss: 1.3503 - val_accuracy: 0.6336\nEpoch 65/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.2451 - accuracy: 0.9132 - val_loss: 1.3341 - val_accuracy: 0.6303\nEpoch 66/250\n448/448 [==============================] - 9s 21ms/step - loss: 0.2372 - accuracy: 0.9181 - val_loss: 1.3330 - val_accuracy: 0.6331\nEpoch 67/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.2344 - accuracy: 0.9176 - val_loss: 1.3304 - val_accuracy: 0.6309\nEpoch 68/250\n448/448 [==============================] - 11s 24ms/step - loss: 0.2274 - accuracy: 0.9217 - val_loss: 1.3618 - val_accuracy: 0.6325\nEpoch 69/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.2171 - accuracy: 0.9252 - val_loss: 1.3822 - val_accuracy: 0.6314\nEpoch 70/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.2170 - accuracy: 0.9221 - val_loss: 1.3889 - val_accuracy: 0.6325\nEpoch 71/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.2050 - accuracy: 0.9292 - val_loss: 1.3699 - val_accuracy: 0.6330\nEpoch 72/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.2093 - accuracy: 0.9264 - val_loss: 1.3706 - val_accuracy: 0.6281\nEpoch 73/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.2033 - accuracy: 0.9307 - val_loss: 1.4081 - val_accuracy: 0.6320\nEpoch 74/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.1931 - accuracy: 0.9302 - val_loss: 1.4176 - val_accuracy: 0.6310\nEpoch 75/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1895 - accuracy: 0.9335 - val_loss: 1.3998 - val_accuracy: 0.6321\nEpoch 76/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1950 - accuracy: 0.9327 - val_loss: 1.4025 - val_accuracy: 0.6316\nEpoch 77/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.1842 - accuracy: 0.9364 - val_loss: 1.4428 - val_accuracy: 0.6290\nEpoch 78/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1788 - accuracy: 0.9381 - val_loss: 1.4424 - val_accuracy: 0.6328\nEpoch 79/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1835 - accuracy: 0.9371 - val_loss: 1.4259 - val_accuracy: 0.6364\nEpoch 80/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1716 - accuracy: 0.9398 - val_loss: 1.4284 - val_accuracy: 0.6324\nEpoch 81/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.1657 - accuracy: 0.9410 - val_loss: 1.4520 - val_accuracy: 0.6343\nEpoch 82/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1745 - accuracy: 0.9401 - val_loss: 1.4682 - val_accuracy: 0.6366\nEpoch 83/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1659 - accuracy: 0.9438 - val_loss: 1.4320 - val_accuracy: 0.6330\nEpoch 84/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.1668 - accuracy: 0.9428 - val_loss: 1.4193 - val_accuracy: 0.6360\nEpoch 85/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1705 - accuracy: 0.9393 - val_loss: 1.5082 - val_accuracy: 0.6367\nEpoch 86/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1565 - accuracy: 0.9465 - val_loss: 1.4523 - val_accuracy: 0.6343\nEpoch 87/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.1539 - accuracy: 0.9459 - val_loss: 1.4793 - val_accuracy: 0.6350\nEpoch 88/250\n448/448 [==============================] - 10s 21ms/step - loss: 0.1455 - accuracy: 0.9513 - val_loss: 1.4918 - val_accuracy: 0.6415\nEpoch 89/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1527 - accuracy: 0.9449 - val_loss: 1.4568 - val_accuracy: 0.6369\nEpoch 90/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1520 - accuracy: 0.9477 - val_loss: 1.4684 - val_accuracy: 0.6352\nEpoch 91/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.1450 - accuracy: 0.9511 - val_loss: 1.4609 - val_accuracy: 0.6356\nEpoch 92/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1461 - accuracy: 0.9491 - val_loss: 1.5475 - val_accuracy: 0.6332\nEpoch 93/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1427 - accuracy: 0.9517 - val_loss: 1.5056 - val_accuracy: 0.6371\nEpoch 94/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.1397 - accuracy: 0.9517 - val_loss: 1.5534 - val_accuracy: 0.6364\nEpoch 95/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1451 - accuracy: 0.9495 - val_loss: 1.5321 - val_accuracy: 0.6342\nEpoch 96/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1432 - accuracy: 0.9498 - val_loss: 1.4941 - val_accuracy: 0.6359\nEpoch 97/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.1312 - accuracy: 0.9551 - val_loss: 1.4979 - val_accuracy: 0.6274\nEpoch 98/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1331 - accuracy: 0.9553 - val_loss: 1.5340 - val_accuracy: 0.6348\nEpoch 99/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1336 - accuracy: 0.9532 - val_loss: 1.5306 - val_accuracy: 0.6370\nEpoch 100/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1221 - accuracy: 0.9578 - val_loss: 1.5555 - val_accuracy: 0.6334\nEpoch 101/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.1318 - accuracy: 0.9553 - val_loss: 1.5275 - val_accuracy: 0.6398\nEpoch 102/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1337 - accuracy: 0.9540 - val_loss: 1.5427 - val_accuracy: 0.6341\nEpoch 103/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1275 - accuracy: 0.9572 - val_loss: 1.5720 - val_accuracy: 0.6327\nEpoch 104/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.1247 - accuracy: 0.9573 - val_loss: 1.5381 - val_accuracy: 0.6286\nEpoch 105/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1301 - accuracy: 0.9554 - val_loss: 1.5765 - val_accuracy: 0.6283\nEpoch 106/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1187 - accuracy: 0.9570 - val_loss: 1.5802 - val_accuracy: 0.6313\nEpoch 107/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.1244 - accuracy: 0.9578 - val_loss: 1.5898 - val_accuracy: 0.6342\nEpoch 108/250\n448/448 [==============================] - 9s 21ms/step - loss: 0.1182 - accuracy: 0.9580 - val_loss: 1.5734 - val_accuracy: 0.6348\nEpoch 109/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1125 - accuracy: 0.9606 - val_loss: 1.5926 - val_accuracy: 0.6330\nEpoch 110/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1185 - accuracy: 0.9615 - val_loss: 1.5938 - val_accuracy: 0.6350\nEpoch 111/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.1209 - accuracy: 0.9586 - val_loss: 1.5872 - val_accuracy: 0.6299\nEpoch 112/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1152 - accuracy: 0.9608 - val_loss: 1.5868 - val_accuracy: 0.6321\nEpoch 113/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1094 - accuracy: 0.9606 - val_loss: 1.6235 - val_accuracy: 0.6300\nEpoch 114/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.1122 - accuracy: 0.9604 - val_loss: 1.5956 - val_accuracy: 0.6338\nEpoch 115/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1173 - accuracy: 0.9589 - val_loss: 1.5775 - val_accuracy: 0.6299\nEpoch 116/250\n448/448 [==============================] - 10s 21ms/step - loss: 0.1064 - accuracy: 0.9629 - val_loss: 1.6228 - val_accuracy: 0.6306\nEpoch 117/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.1114 - accuracy: 0.9614 - val_loss: 1.6181 - val_accuracy: 0.6327\nEpoch 118/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1086 - accuracy: 0.9621 - val_loss: 1.5887 - val_accuracy: 0.6335\nEpoch 119/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1058 - accuracy: 0.9642 - val_loss: 1.6588 - val_accuracy: 0.6285\nEpoch 120/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0980 - accuracy: 0.9655 - val_loss: 1.6341 - val_accuracy: 0.6277\nEpoch 121/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.1079 - accuracy: 0.9624 - val_loss: 1.6291 - val_accuracy: 0.6292\nEpoch 122/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1081 - accuracy: 0.9623 - val_loss: 1.6443 - val_accuracy: 0.6324\nEpoch 123/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.1033 - accuracy: 0.9649 - val_loss: 1.6226 - val_accuracy: 0.6324\nEpoch 124/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.1023 - accuracy: 0.9641 - val_loss: 1.6353 - val_accuracy: 0.6335\nEpoch 125/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0965 - accuracy: 0.9663 - val_loss: 1.6795 - val_accuracy: 0.6338\nEpoch 126/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0963 - accuracy: 0.9672 - val_loss: 1.6828 - val_accuracy: 0.6327\nEpoch 127/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.1005 - accuracy: 0.9653 - val_loss: 1.6612 - val_accuracy: 0.6336\nEpoch 128/250\n448/448 [==============================] - 10s 21ms/step - loss: 0.0950 - accuracy: 0.9677 - val_loss: 1.6648 - val_accuracy: 0.6335\nEpoch 129/250\n448/448 [==============================] - 10s 21ms/step - loss: 0.1019 - accuracy: 0.9648 - val_loss: 1.6789 - val_accuracy: 0.6304\nEpoch 130/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0966 - accuracy: 0.9661 - val_loss: 1.6967 - val_accuracy: 0.6296\nEpoch 131/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0909 - accuracy: 0.9694 - val_loss: 1.6687 - val_accuracy: 0.6342\nEpoch 132/250\n448/448 [==============================] - 10s 21ms/step - loss: 0.1023 - accuracy: 0.9650 - val_loss: 1.6598 - val_accuracy: 0.6330\nEpoch 133/250\n448/448 [==============================] - 10s 21ms/step - loss: 0.0932 - accuracy: 0.9672 - val_loss: 1.6711 - val_accuracy: 0.6336\nEpoch 134/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0905 - accuracy: 0.9695 - val_loss: 1.6463 - val_accuracy: 0.6334\nEpoch 135/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0931 - accuracy: 0.9692 - val_loss: 1.6866 - val_accuracy: 0.6307\nEpoch 136/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0943 - accuracy: 0.9680 - val_loss: 1.6446 - val_accuracy: 0.6356\nEpoch 137/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0952 - accuracy: 0.9679 - val_loss: 1.6761 - val_accuracy: 0.6338\nEpoch 138/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0906 - accuracy: 0.9688 - val_loss: 1.6677 - val_accuracy: 0.6336\nEpoch 139/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0915 - accuracy: 0.9677 - val_loss: 1.6801 - val_accuracy: 0.6348\nEpoch 140/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0943 - accuracy: 0.9682 - val_loss: 1.7560 - val_accuracy: 0.6317\nEpoch 141/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0869 - accuracy: 0.9707 - val_loss: 1.7161 - val_accuracy: 0.6324\nEpoch 142/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0964 - accuracy: 0.9665 - val_loss: 1.6836 - val_accuracy: 0.6363\nEpoch 143/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0849 - accuracy: 0.9709 - val_loss: 1.7052 - val_accuracy: 0.6399\nEpoch 144/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0849 - accuracy: 0.9713 - val_loss: 1.7443 - val_accuracy: 0.6348\nEpoch 145/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0844 - accuracy: 0.9722 - val_loss: 1.7287 - val_accuracy: 0.6363\nEpoch 146/250\n448/448 [==============================] - 10s 21ms/step - loss: 0.0852 - accuracy: 0.9711 - val_loss: 1.6770 - val_accuracy: 0.6356\nEpoch 147/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0817 - accuracy: 0.9728 - val_loss: 1.7477 - val_accuracy: 0.6330\nEpoch 148/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0835 - accuracy: 0.9710 - val_loss: 1.7074 - val_accuracy: 0.6332\nEpoch 149/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0853 - accuracy: 0.9725 - val_loss: 1.7413 - val_accuracy: 0.6334\nEpoch 150/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0888 - accuracy: 0.9697 - val_loss: 1.7140 - val_accuracy: 0.6321\nEpoch 151/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0809 - accuracy: 0.9739 - val_loss: 1.7581 - val_accuracy: 0.6364\nEpoch 152/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0810 - accuracy: 0.9727 - val_loss: 1.7311 - val_accuracy: 0.6346\nEpoch 153/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0800 - accuracy: 0.9725 - val_loss: 1.7633 - val_accuracy: 0.6324\nEpoch 154/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0802 - accuracy: 0.9732 - val_loss: 1.7366 - val_accuracy: 0.6360\nEpoch 155/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0776 - accuracy: 0.9726 - val_loss: 1.7821 - val_accuracy: 0.6313\nEpoch 156/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0812 - accuracy: 0.9721 - val_loss: 1.7428 - val_accuracy: 0.6364\nEpoch 157/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0805 - accuracy: 0.9718 - val_loss: 1.7559 - val_accuracy: 0.6353\nEpoch 158/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0854 - accuracy: 0.9702 - val_loss: 1.7690 - val_accuracy: 0.6327\nEpoch 159/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0838 - accuracy: 0.9721 - val_loss: 1.6943 - val_accuracy: 0.6367\nEpoch 160/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0773 - accuracy: 0.9745 - val_loss: 1.7153 - val_accuracy: 0.6332\nEpoch 161/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0761 - accuracy: 0.9743 - val_loss: 1.7929 - val_accuracy: 0.6385\nEpoch 162/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0780 - accuracy: 0.9749 - val_loss: 1.7995 - val_accuracy: 0.6332\nEpoch 163/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0827 - accuracy: 0.9722 - val_loss: 1.7904 - val_accuracy: 0.6346\nEpoch 164/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0794 - accuracy: 0.9738 - val_loss: 1.7407 - val_accuracy: 0.6330\nEpoch 165/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0798 - accuracy: 0.9726 - val_loss: 1.7694 - val_accuracy: 0.6331\nEpoch 166/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0758 - accuracy: 0.9733 - val_loss: 1.7454 - val_accuracy: 0.6324\nEpoch 167/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0798 - accuracy: 0.9730 - val_loss: 1.7331 - val_accuracy: 0.6300\nEpoch 168/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0766 - accuracy: 0.9728 - val_loss: 1.8263 - val_accuracy: 0.6316\nEpoch 169/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0715 - accuracy: 0.9759 - val_loss: 1.8247 - val_accuracy: 0.6324\nEpoch 170/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0675 - accuracy: 0.9761 - val_loss: 1.7826 - val_accuracy: 0.6306\nEpoch 171/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0795 - accuracy: 0.9718 - val_loss: 1.7132 - val_accuracy: 0.6362\nEpoch 172/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0729 - accuracy: 0.9759 - val_loss: 1.7980 - val_accuracy: 0.6339\nEpoch 173/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0833 - accuracy: 0.9726 - val_loss: 1.7267 - val_accuracy: 0.6342\nEpoch 174/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0742 - accuracy: 0.9749 - val_loss: 1.7783 - val_accuracy: 0.6330\nEpoch 175/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0691 - accuracy: 0.9766 - val_loss: 1.7916 - val_accuracy: 0.6338\nEpoch 176/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0745 - accuracy: 0.9744 - val_loss: 1.7836 - val_accuracy: 0.6338\nEpoch 177/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0726 - accuracy: 0.9752 - val_loss: 1.7892 - val_accuracy: 0.6293\nEpoch 178/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0794 - accuracy: 0.9726 - val_loss: 1.8038 - val_accuracy: 0.6330\nEpoch 179/250\n448/448 [==============================] - 9s 21ms/step - loss: 0.0694 - accuracy: 0.9780 - val_loss: 1.8333 - val_accuracy: 0.6328\nEpoch 180/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0731 - accuracy: 0.9733 - val_loss: 1.8236 - val_accuracy: 0.6316\nEpoch 181/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0682 - accuracy: 0.9770 - val_loss: 1.8261 - val_accuracy: 0.6310\nEpoch 182/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0681 - accuracy: 0.9773 - val_loss: 1.7814 - val_accuracy: 0.6390\nEpoch 183/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0676 - accuracy: 0.9749 - val_loss: 1.8038 - val_accuracy: 0.6359\nEpoch 184/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0713 - accuracy: 0.9754 - val_loss: 1.7997 - val_accuracy: 0.6295\nEpoch 185/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0685 - accuracy: 0.9762 - val_loss: 1.8058 - val_accuracy: 0.6324\nEpoch 186/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0714 - accuracy: 0.9761 - val_loss: 1.7804 - val_accuracy: 0.6323\nEpoch 187/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0667 - accuracy: 0.9760 - val_loss: 1.8020 - val_accuracy: 0.6313\nEpoch 188/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0631 - accuracy: 0.9772 - val_loss: 1.8058 - val_accuracy: 0.6297\nEpoch 189/250\n448/448 [==============================] - 10s 21ms/step - loss: 0.0707 - accuracy: 0.9756 - val_loss: 1.8431 - val_accuracy: 0.6300\nEpoch 190/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0698 - accuracy: 0.9762 - val_loss: 1.8269 - val_accuracy: 0.6339\nEpoch 191/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0700 - accuracy: 0.9774 - val_loss: 1.7895 - val_accuracy: 0.6310\nEpoch 192/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0699 - accuracy: 0.9777 - val_loss: 1.7621 - val_accuracy: 0.6327\nEpoch 193/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0702 - accuracy: 0.9759 - val_loss: 1.7738 - val_accuracy: 0.6356\nEpoch 194/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0638 - accuracy: 0.9784 - val_loss: 1.8304 - val_accuracy: 0.6355\nEpoch 195/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0626 - accuracy: 0.9781 - val_loss: 1.8168 - val_accuracy: 0.6342\nEpoch 196/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0655 - accuracy: 0.9770 - val_loss: 1.7970 - val_accuracy: 0.6371\nEpoch 197/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0646 - accuracy: 0.9771 - val_loss: 1.8722 - val_accuracy: 0.6349\nEpoch 198/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0620 - accuracy: 0.9788 - val_loss: 1.8954 - val_accuracy: 0.6278\nEpoch 199/250\n448/448 [==============================] - 9s 21ms/step - loss: 0.0646 - accuracy: 0.9789 - val_loss: 1.7872 - val_accuracy: 0.6355\nEpoch 200/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0670 - accuracy: 0.9780 - val_loss: 1.8314 - val_accuracy: 0.6288\nEpoch 201/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0622 - accuracy: 0.9790 - val_loss: 1.8102 - val_accuracy: 0.6325\nEpoch 202/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0698 - accuracy: 0.9755 - val_loss: 1.8399 - val_accuracy: 0.6341\nEpoch 203/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0592 - accuracy: 0.9804 - val_loss: 1.8134 - val_accuracy: 0.6306\nEpoch 204/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0651 - accuracy: 0.9781 - val_loss: 1.8716 - val_accuracy: 0.6348\nEpoch 205/250\n448/448 [==============================] - 11s 24ms/step - loss: 0.0638 - accuracy: 0.9777 - val_loss: 1.8309 - val_accuracy: 0.6345\nEpoch 206/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0618 - accuracy: 0.9787 - val_loss: 1.8165 - val_accuracy: 0.6338\nEpoch 207/250\n448/448 [==============================] - 11s 24ms/step - loss: 0.0600 - accuracy: 0.9796 - val_loss: 1.8624 - val_accuracy: 0.6335\nEpoch 208/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0628 - accuracy: 0.9772 - val_loss: 1.8700 - val_accuracy: 0.6310\nEpoch 209/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0631 - accuracy: 0.9788 - val_loss: 1.8205 - val_accuracy: 0.6336\nEpoch 210/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0679 - accuracy: 0.9763 - val_loss: 1.8122 - val_accuracy: 0.6345\nEpoch 211/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0545 - accuracy: 0.9823 - val_loss: 1.8904 - val_accuracy: 0.6331\nEpoch 212/250\n448/448 [==============================] - 9s 21ms/step - loss: 0.0632 - accuracy: 0.9784 - val_loss: 1.8334 - val_accuracy: 0.6311\nEpoch 213/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0651 - accuracy: 0.9768 - val_loss: 1.8137 - val_accuracy: 0.6357\nEpoch 214/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0605 - accuracy: 0.9787 - val_loss: 1.8210 - val_accuracy: 0.6286\nEpoch 215/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0590 - accuracy: 0.9798 - val_loss: 1.8656 - val_accuracy: 0.6299\nEpoch 216/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0623 - accuracy: 0.9789 - val_loss: 1.8454 - val_accuracy: 0.6334\nEpoch 217/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0584 - accuracy: 0.9803 - val_loss: 1.9083 - val_accuracy: 0.6339\nEpoch 218/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0600 - accuracy: 0.9784 - val_loss: 1.8677 - val_accuracy: 0.6297\nEpoch 219/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0591 - accuracy: 0.9800 - val_loss: 1.8422 - val_accuracy: 0.6353\nEpoch 220/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0660 - accuracy: 0.9769 - val_loss: 1.8439 - val_accuracy: 0.6318\nEpoch 221/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0598 - accuracy: 0.9789 - val_loss: 1.8605 - val_accuracy: 0.6348\nEpoch 222/250\n448/448 [==============================] - 10s 21ms/step - loss: 0.0641 - accuracy: 0.9775 - val_loss: 1.8467 - val_accuracy: 0.6359\nEpoch 223/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0564 - accuracy: 0.9806 - val_loss: 1.8540 - val_accuracy: 0.6341\nEpoch 224/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0641 - accuracy: 0.9776 - val_loss: 1.8433 - val_accuracy: 0.6362\nEpoch 225/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0532 - accuracy: 0.9809 - val_loss: 1.8491 - val_accuracy: 0.6320\nEpoch 226/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0569 - accuracy: 0.9808 - val_loss: 1.8303 - val_accuracy: 0.6349\nEpoch 227/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0588 - accuracy: 0.9788 - val_loss: 1.9028 - val_accuracy: 0.6304\nEpoch 228/250\n448/448 [==============================] - 11s 24ms/step - loss: 0.0587 - accuracy: 0.9808 - val_loss: 1.8356 - val_accuracy: 0.6303\nEpoch 229/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0554 - accuracy: 0.9814 - val_loss: 1.9595 - val_accuracy: 0.6384\nEpoch 230/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0558 - accuracy: 0.9797 - val_loss: 1.9001 - val_accuracy: 0.6328\nEpoch 231/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0550 - accuracy: 0.9815 - val_loss: 1.8563 - val_accuracy: 0.6398\nEpoch 232/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0521 - accuracy: 0.9830 - val_loss: 1.8232 - val_accuracy: 0.6341\nEpoch 233/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0560 - accuracy: 0.9810 - val_loss: 1.8469 - val_accuracy: 0.6353\nEpoch 234/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0562 - accuracy: 0.9812 - val_loss: 1.8471 - val_accuracy: 0.6318\nEpoch 235/250\n448/448 [==============================] - 11s 24ms/step - loss: 0.0655 - accuracy: 0.9788 - val_loss: 1.8800 - val_accuracy: 0.6324\nEpoch 236/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0505 - accuracy: 0.9828 - val_loss: 1.8814 - val_accuracy: 0.6316\nEpoch 237/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0594 - accuracy: 0.9793 - val_loss: 1.8880 - val_accuracy: 0.6316\nEpoch 238/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0569 - accuracy: 0.9802 - val_loss: 1.8995 - val_accuracy: 0.6327\nEpoch 239/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0564 - accuracy: 0.9801 - val_loss: 1.9020 - val_accuracy: 0.6356\nEpoch 240/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0577 - accuracy: 0.9802 - val_loss: 1.8033 - val_accuracy: 0.6348\nEpoch 241/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0570 - accuracy: 0.9811 - val_loss: 1.8821 - val_accuracy: 0.6323\nEpoch 242/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0530 - accuracy: 0.9817 - val_loss: 1.8603 - val_accuracy: 0.6343\nEpoch 243/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0513 - accuracy: 0.9821 - val_loss: 1.8651 - val_accuracy: 0.6316\nEpoch 244/250\n448/448 [==============================] - 10s 21ms/step - loss: 0.0496 - accuracy: 0.9829 - val_loss: 1.8742 - val_accuracy: 0.6313\nEpoch 245/250\n448/448 [==============================] - 11s 24ms/step - loss: 0.0533 - accuracy: 0.9823 - val_loss: 1.8846 - val_accuracy: 0.6359\nEpoch 246/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0535 - accuracy: 0.9812 - val_loss: 1.8991 - val_accuracy: 0.6388\nEpoch 247/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0540 - accuracy: 0.9813 - val_loss: 1.8924 - val_accuracy: 0.6350\nEpoch 248/250\n448/448 [==============================] - 10s 23ms/step - loss: 0.0547 - accuracy: 0.9811 - val_loss: 1.9503 - val_accuracy: 0.6349\nEpoch 249/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0492 - accuracy: 0.9821 - val_loss: 1.9252 - val_accuracy: 0.6370\nEpoch 250/250\n448/448 [==============================] - 10s 22ms/step - loss: 0.0496 - accuracy: 0.9831 - val_loss: 1.8430 - val_accuracy: 0.6353\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save_weights('model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-08-28T19:09:23.933037Z","iopub.execute_input":"2021-08-28T19:09:23.933414Z","iopub.status.idle":"2021-08-28T19:09:23.974227Z","shell.execute_reply.started":"2021-08-28T19:09:23.933379Z","shell.execute_reply":"2021-08-28T19:09:23.973392Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"import cv2","metadata":{"execution":{"iopub.status.busy":"2021-08-28T19:17:35.038623Z","iopub.execute_input":"2021-08-28T19:17:35.038998Z","iopub.status.idle":"2021-08-28T19:17:35.192090Z","shell.execute_reply.started":"2021-08-28T19:17:35.038963Z","shell.execute_reply":"2021-08-28T19:17:35.191251Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"model.load_weights('./model.h5')\ncv2.ocl.setUseOpenCL(False)\n\nemotion_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}\n\ncap = cv2.VideoCapture(1)\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n    facecasc = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n    faces = facecasc.detectMultiScale(gray,scaleFactor=1.3, minNeighbors=5)\n\n    for (x, y, w, h) in faces:\n        cv2.rectangle(frame, (x, y-50), (x+w, y+h+10), (255, 0, 0), 2)\n        roi_gray = gray[y:y + h, x:x + w]\n        cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (48, 48)), -1), 0)\n        prediction = model.predict(cropped_img)\n        maxindex = int(np.argmax(prediction))\n        cv2.putText(frame, emotion_dict[maxindex], (x+20, y-60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n\n    cv2.imshow('Video', cv2.resize(frame,(1600,960),interpolation = cv2.INTER_CUBIC))\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\ncv2.destroyAllWindows()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T17:51:20.011893Z","iopub.execute_input":"2021-08-28T17:51:20.012226Z","iopub.status.idle":"2021-08-28T17:51:20.044492Z","shell.execute_reply.started":"2021-08-28T17:51:20.012195Z","shell.execute_reply":"2021-08-28T17:51:20.043620Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}